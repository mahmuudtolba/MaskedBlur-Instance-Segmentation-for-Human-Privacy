{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget --quiet http://sceneparsing.csail.mit.edu/data/ChallengeData2017/images.tar\n!wget --quiet http://sceneparsing.csail.mit.edu/data/ChallengeData2017/annotations_instance.tar\n!tar -xf images.tar\n!tar -xf annotations_instance.tar\n!rm images.tar annotations_instance.tar","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-13T08:40:55.547348Z","iopub.execute_input":"2024-02-13T08:40:55.548089Z","iopub.status.idle":"2024-02-13T08:47:58.447760Z","shell.execute_reply.started":"2024-02-13T08:40:55.548050Z","shell.execute_reply":"2024-02-13T08:47:58.446632Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport time\nimport random\nimport collections\nimport glob\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\n\nimport torch\nimport torchvision\nimport torchvision.transforms as T\nfrom torchvision.transforms import ToPILImage\nfrom torchvision.transforms import functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection.mask_rcnn import MaskRCNNPredictor","metadata":{"execution":{"iopub.status.busy":"2024-02-13T08:50:43.275766Z","iopub.execute_input":"2024-02-13T08:50:43.276796Z","iopub.status.idle":"2024-02-13T08:50:43.283941Z","shell.execute_reply.started":"2024-02-13T08:50:43.276752Z","shell.execute_reply":"2024-02-13T08:50:43.282716Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"WIDTH = 704\nHEIGHT = 520\n\n# Reduced the train dataset to 5000 rows\nTEST = False\n\nDEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\nRESNET_MEAN = (0.485, 0.456, 0.406)\nRESNET_STD = (0.229, 0.224, 0.225)\n\nBATCH_SIZE = 8\n\n# No changes tried with the optimizer yet.\nMOMENTUM = 0.9\nLEARNING_RATE = 0.005\nWEIGHT_DECAY = 0.0005\n\n\n# Changes the confidence required for a pixel to be kept for a mask.\n# Only used 0.5 till now.\nMASK_THRESHOLD = 0.5\n\n# Normalize to resnet mean and std if True.\nNORMALIZE = False\n\n\n# Use a StepLR scheduler if True. Not tried yet.\nUSE_SCHEDULER = False\n\n# Number of epochs\nNUM_EPOCHS = 1\n\n\nBOX_DETECTIONS_PER_IMG = 539\n\n\nMIN_SCORE = 0.59","metadata":{"execution":{"iopub.status.busy":"2024-02-13T08:50:44.543829Z","iopub.execute_input":"2024-02-13T08:50:44.544200Z","iopub.status.idle":"2024-02-13T08:50:44.551028Z","shell.execute_reply.started":"2024-02-13T08:50:44.544169Z","shell.execute_reply":"2024-02-13T08:50:44.550090Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"all_images = glob.glob('/kaggle/working/images/training/*.jpg')\nall_annots = glob.glob('/kaggle/working/annotations_instance/training/*.png')","metadata":{"execution":{"iopub.status.busy":"2024-02-13T08:52:10.544969Z","iopub.execute_input":"2024-02-13T08:52:10.545410Z","iopub.status.idle":"2024-02-13T08:52:10.691931Z","shell.execute_reply.started":"2024-02-13T08:52:10.545376Z","shell.execute_reply":"2024-02-13T08:52:10.691040Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"annots = []\nfor ann in tqdm(all_annots):\n    _ann = np.array(Image.open(ann).convert(\"RGB\")).transpose(2,0,1)\n    r , g ,b  = _ann\n    if 4 not in np.unique(r):\n        continue\n    annots.append(ann)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T08:52:11.858779Z","iopub.execute_input":"2024-02-13T08:52:11.859141Z","iopub.status.idle":"2024-02-13T08:54:18.263803Z","shell.execute_reply.started":"2024-02-13T08:52:11.859111Z","shell.execute_reply":"2024-02-13T08:54:18.262858Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"100%|██████████| 20210/20210 [02:06<00:00, 159.90it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n_annots = [annot.split('/')[-1].split('.')[0] for annot in annots ]\ntrn_items,val_items=train_test_split(_annots,random_state=2)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T08:54:18.265717Z","iopub.execute_input":"2024-02-13T08:54:18.266725Z","iopub.status.idle":"2024-02-13T08:54:18.278545Z","shell.execute_reply.started":"2024-02-13T08:54:18.266684Z","shell.execute_reply":"2024-02-13T08:54:18.277565Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# These are slight redefinitions of torch.transformation classes\n# The difference is that they handle the target and the mask\n# Copied from Abishek, added new ones\nclass Compose:\n    def __init__(self, transforms):\n        self.transforms = transforms\n\n    def __call__(self, image, target):\n        for t in self.transforms:\n            image, target = t(image, target)\n        return image, target\n\nclass VerticalFlip:\n    def __init__(self, prob):\n        self.prob = prob\n\n    def __call__(self, image, target):\n        if random.random() < self.prob:\n            height, width = image.shape[-2:]\n            image = image.flip(-2)\n            bbox = target[\"boxes\"]\n            bbox[:, [1, 3]] = height - bbox[:, [3, 1]]\n            target[\"boxes\"] = bbox\n            target[\"masks\"] = target[\"masks\"].flip(-2)\n        return image, target\n\nclass HorizontalFlip:\n    def __init__(self, prob):\n        self.prob = prob\n\n    def __call__(self, image, target):\n        if random.random() < self.prob:\n            height, width = image.shape[-2:]\n            image = image.flip(-1)\n            bbox = target[\"boxes\"]\n            bbox[:, [0, 2]] = width - bbox[:, [2, 0]]\n            target[\"boxes\"] = bbox\n            target[\"masks\"] = target[\"masks\"].flip(-1)\n        return image, target\n\nclass Normalize:\n    def __call__(self, image, target):\n        image = F.normalize(image, RESNET_MEAN, RESNET_STD)\n        return image, target\n\nclass ToTensor:\n    def __call__(self, image, target):\n        image = F.to_tensor(image)\n        return image, target\n\n\ndef get_transform(train):\n    transforms = [ToTensor()]\n    if NORMALIZE:\n        transforms.append(Normalize())\n    return Compose(transforms)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T08:54:19.683278Z","iopub.execute_input":"2024-02-13T08:54:19.683622Z","iopub.status.idle":"2024-02-13T08:54:19.696660Z","shell.execute_reply.started":"2024-02-13T08:54:19.683596Z","shell.execute_reply":"2024-02-13T08:54:19.695724Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class MasksDataset(Dataset):\n\n    def __init__(self, items, transforms, N):\n        self.items = items\n        self.transforms = transforms\n        self.N = N\n\n    def get_mask(self, path):\n        an = np.array(Image.open(path).convert(\"RGB\")).transpose(2,0,1)\n        r,g,b = an\n        nzs = np.nonzero(r==4)\n        instances = np.unique(g[nzs])\n        masks = np.zeros((len(instances), *r.shape))\n        for ix,_id in enumerate(instances):\n            masks[ix] = g==_id\n        return masks\n\n    def __getitem__(self, ix):\n        _id = self.items[ix]\n        img_path = f'images/training/{_id}.jpg'\n        mask_path = f'annotations_instance/training/{_id}.png'\n        masks = self.get_mask(mask_path)\n        obj_ids = np.arange(1, len(masks)+1)\n        img = np.array(Image.open(img_path).convert(\"RGB\"))\n        num_objs = len(obj_ids)\n        boxes = []\n        for i in range(num_objs):\n            obj_pixels = np.where(masks[i])\n            xmin = np.min(obj_pixels[1])\n            xmax = np.max(obj_pixels[1])\n            ymin = np.min(obj_pixels[0])\n            ymax = np.max(obj_pixels[0])\n            if (((xmax-xmin)<=10) | (ymax-ymin)<=10):\n                xmax = xmin+10\n                ymax = ymin+10\n            boxes.append([xmin, ymin, xmax, ymax])\n        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n        labels = torch.ones((num_objs,), dtype=torch.int64)\n        masks = torch.as_tensor(masks, dtype=torch.uint8)\n        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n        image_id = torch.tensor([ix])\n        target = {}\n        target[\"boxes\"] = boxes\n        target[\"labels\"] = labels\n        target[\"masks\"] = masks\n        target[\"image_id\"] = image_id\n        target[\"area\"] = area\n        target[\"iscrowd\"] = iscrowd\n        if self.transforms is not None:\n            img, target = self.transforms(img, target)\n        return img, target\n\n    def __len__(self):\n        return self.N\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T08:54:22.847049Z","iopub.execute_input":"2024-02-13T08:54:22.847790Z","iopub.status.idle":"2024-02-13T08:54:22.862381Z","shell.execute_reply.started":"2024-02-13T08:54:22.847754Z","shell.execute_reply":"2024-02-13T08:54:22.861442Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def get_model_instance_segmentation(num_classes):\n    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained = True)\n    in_features = model.roi_heads.box_predictor.cls_score.in_features\n    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n\n    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n    hidden_layer = 256\n    # Replace the mask predictor with a new one\n    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n                                                       hidden_layer,num_classes)\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-02-13T08:54:32.641473Z","iopub.execute_input":"2024-02-13T08:54:32.641873Z","iopub.status.idle":"2024-02-13T08:54:32.648205Z","shell.execute_reply.started":"2024-02-13T08:54:32.641841Z","shell.execute_reply":"2024-02-13T08:54:32.647176Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model = get_model_instance_segmentation(2).to(DEVICE)\nmodel","metadata":{"execution":{"iopub.status.busy":"2024-02-13T08:54:34.173277Z","iopub.execute_input":"2024-02-13T08:54:34.173974Z","iopub.status.idle":"2024-02-13T08:54:36.561389Z","shell.execute_reply.started":"2024-02-13T08:54:34.173937Z","shell.execute_reply":"2024-02-13T08:54:36.560537Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MaskRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to /root/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n100%|██████████| 170M/170M [00:01<00:00, 149MB/s]  \n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"MaskRCNN(\n  (transform): GeneralizedRCNNTransform(\n      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n  )\n  (backbone): BackboneWithFPN(\n    (body): IntermediateLayerGetter(\n      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n      (relu): ReLU(inplace=True)\n      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (layer1): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): FrozenBatchNorm2d(256, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer2): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): FrozenBatchNorm2d(512, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (3): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer3): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): FrozenBatchNorm2d(1024, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (3): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (4): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (5): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer4): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): FrozenBatchNorm2d(2048, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n    )\n    (fpn): FeaturePyramidNetwork(\n      (inner_blocks): ModuleList(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (2): Conv2dNormActivation(\n          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (layer_blocks): ModuleList(\n        (0-3): 4 x Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (extra_blocks): LastLevelMaxPool()\n    )\n  )\n  (rpn): RegionProposalNetwork(\n    (anchor_generator): AnchorGenerator()\n    (head): RPNHead(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n        )\n      )\n      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n  (roi_heads): RoIHeads(\n    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n    (box_head): TwoMLPHead(\n      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n    )\n    (box_predictor): FastRCNNPredictor(\n      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n    )\n    (mask_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n    (mask_head): MaskRCNNHeads(\n      (0): Conv2dNormActivation(\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): ReLU(inplace=True)\n      )\n      (1): Conv2dNormActivation(\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): ReLU(inplace=True)\n      )\n      (2): Conv2dNormActivation(\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): ReLU(inplace=True)\n      )\n      (3): Conv2dNormActivation(\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): ReLU(inplace=True)\n      )\n    )\n    (mask_predictor): MaskRCNNPredictor(\n      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n      (relu): ReLU(inplace=True)\n      (mask_fcn_logits): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"dataset = MasksDataset(trn_items, get_transform(train=True), N=len(trn_items),)\ndataset_test = MasksDataset(val_items, get_transform(train=False), N=len(val_items))\n\n\n# define training and validation data loaders\ndata_loader = torch.utils.data.DataLoader(\n    dataset, batch_size=8, shuffle=True, num_workers=0,\n    collate_fn=lambda x: tuple(zip(*x)))\n\ndata_loader_test = torch.utils.data.DataLoader(\n    dataset_test, batch_size=8, shuffle=False, num_workers=0,\n    collate_fn= lambda x: tuple(zip(*x)))","metadata":{"execution":{"iopub.status.busy":"2024-02-13T08:54:53.230947Z","iopub.execute_input":"2024-02-13T08:54:53.231780Z","iopub.status.idle":"2024-02-13T08:54:53.238428Z","shell.execute_reply.started":"2024-02-13T08:54:53.231744Z","shell.execute_reply":"2024-02-13T08:54:53.237260Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"params = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.SGD(params, lr=LEARNING_RATE,\n                                    momentum=MOMENTUM\n                                  , weight_decay=WEIGHT_DECAY)\n# and a learning rate scheduler\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n                                                step_size=3,\n                                                gamma=0.1)\n\n\nn_batches = len(data_loader)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T08:54:54.158334Z","iopub.execute_input":"2024-02-13T08:54:54.158717Z","iopub.status.idle":"2024-02-13T08:54:54.166463Z","shell.execute_reply.started":"2024-02-13T08:54:54.158686Z","shell.execute_reply":"2024-02-13T08:54:54.165481Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"for epoch in range(1, NUM_EPOCHS + 1):\n    print(f\"Starting epoch {epoch} of {NUM_EPOCHS}\")\n    model.train()\n    time_start = time.time()\n\n    train_loss_accum = 0.0\n    train_loss_mask_accum = 0.0\n\n    valid_loss_accum = 0.0\n    valid_loss_mask_accum = 0.0\n\n    for batch_idx, (images, targets) in enumerate(data_loader, 1):\n\n        # Predict\n        images = list(image.to(DEVICE) for image in images)\n        targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n\n        train_loss_dict = model(images, targets)\n        train_loss = sum(loss for loss in train_loss_dict.values())\n\n        # Backprop\n        optimizer.zero_grad()\n        train_loss.backward()\n        optimizer.step()\n\n        # Logging\n        train_loss_mask = train_loss_dict['loss_mask'].item()\n        train_loss_accum += train_loss.item()\n        train_loss_mask_accum += train_loss_mask\n\n        if batch_idx % 50 == 0:\n          print(f\"    [Batch {batch_idx:3d} / {n_batches:3d}] Batch train loss: {train_loss.item():7.3f}. Mask-only loss: {train_loss_mask:7.3f}\")\n\n\n    with torch.no_grad():\n      for batch_idx, (images, targets) in enumerate(data_loader_test, 1):\n          # Predict\n          images = list(image.to(DEVICE) for image in images)\n          targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n\n          valid_loss_dict = model(images, targets)\n          valid_loss = sum(loss for loss in valid_loss_dict.values())\n\n          # Logging\n          valid_loss_mask = valid_loss_dict['loss_mask'].item()\n          valid_loss_accum += valid_loss.item()\n          valid_loss_mask_accum += valid_loss_mask\n\n\n\n    if USE_SCHEDULER:\n        lr_scheduler.step()\n\n    # Train losses\n    train_loss = train_loss_accum / n_batches\n    train_loss_mask = train_loss_mask_accum / n_batches\n\n    valid_loss = valid_loss_accum / n_batches\n    valid_loss_mask = valid_loss_mask_accum / n_batches\n\n    elapsed = time.time() - time_start\n\n\n    torch.save(model.state_dict(), f\"pytorch_model-e{epoch}.bin\")\n    prefix = f\"[Epoch {epoch:2d} / {NUM_EPOCHS:2d}]\"\n    print(f\"{prefix} Train mask-only loss: {train_loss_mask:7.3f}\")\n    print(f\"{prefix} Train loss: {train_loss:7.3f}. [{elapsed:.0f} secs]\")\n    print(f\"{prefix} Valid mask-only loss: {valid_loss_mask:7.3f}\")\n    print(f\"{prefix} Valid loss: {valid_loss:7.3f}. [{elapsed:.0f} secs]\")","metadata":{"execution":{"iopub.status.busy":"2024-02-13T08:54:56.559195Z","iopub.execute_input":"2024-02-13T08:54:56.559913Z","iopub.status.idle":"2024-02-13T09:10:22.483218Z","shell.execute_reply.started":"2024-02-13T08:54:56.559878Z","shell.execute_reply":"2024-02-13T09:10:22.482306Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Starting epoch \u001b[1;36m1\u001b[0m of \u001b[1;36m1\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Starting epoch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"    \u001b[1m[\u001b[0mBatch  \u001b[1;36m50\u001b[0m \u001b[35m/\u001b[0m \u001b[1;36m476\u001b[0m\u001b[1m]\u001b[0m Batch train loss:   \u001b[1;36m1.015\u001b[0m. Mask-only loss:   \u001b[1;36m0.388\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    <span style=\"font-weight: bold\">[</span>Batch  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">476</span><span style=\"font-weight: bold\">]</span> Batch train loss:   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.015</span>. Mask-only loss:   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.388</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"    \u001b[1m[\u001b[0mBatch \u001b[1;36m100\u001b[0m \u001b[35m/\u001b[0m \u001b[1;36m476\u001b[0m\u001b[1m]\u001b[0m Batch train loss:   \u001b[1;36m0.566\u001b[0m. Mask-only loss:   \u001b[1;36m0.297\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    <span style=\"font-weight: bold\">[</span>Batch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">476</span><span style=\"font-weight: bold\">]</span> Batch train loss:   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.566</span>. Mask-only loss:   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.297</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"    \u001b[1m[\u001b[0mBatch \u001b[1;36m150\u001b[0m \u001b[35m/\u001b[0m \u001b[1;36m476\u001b[0m\u001b[1m]\u001b[0m Batch train loss:   \u001b[1;36m0.736\u001b[0m. Mask-only loss:   \u001b[1;36m0.303\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    <span style=\"font-weight: bold\">[</span>Batch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">150</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">476</span><span style=\"font-weight: bold\">]</span> Batch train loss:   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.736</span>. Mask-only loss:   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.303</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"    \u001b[1m[\u001b[0mBatch \u001b[1;36m200\u001b[0m \u001b[35m/\u001b[0m \u001b[1;36m476\u001b[0m\u001b[1m]\u001b[0m Batch train loss:   \u001b[1;36m0.606\u001b[0m. Mask-only loss:   \u001b[1;36m0.355\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    <span style=\"font-weight: bold\">[</span>Batch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">476</span><span style=\"font-weight: bold\">]</span> Batch train loss:   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.606</span>. Mask-only loss:   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.355</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"    \u001b[1m[\u001b[0mBatch \u001b[1;36m250\u001b[0m \u001b[35m/\u001b[0m \u001b[1;36m476\u001b[0m\u001b[1m]\u001b[0m Batch train loss:   \u001b[1;36m0.926\u001b[0m. Mask-only loss:   \u001b[1;36m0.351\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    <span style=\"font-weight: bold\">[</span>Batch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">250</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">476</span><span style=\"font-weight: bold\">]</span> Batch train loss:   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.926</span>. Mask-only loss:   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.351</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"    \u001b[1m[\u001b[0mBatch \u001b[1;36m300\u001b[0m \u001b[35m/\u001b[0m \u001b[1;36m476\u001b[0m\u001b[1m]\u001b[0m Batch train loss:   \u001b[1;36m0.719\u001b[0m. Mask-only loss:   \u001b[1;36m0.348\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    <span style=\"font-weight: bold\">[</span>Batch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">476</span><span style=\"font-weight: bold\">]</span> Batch train loss:   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.719</span>. Mask-only loss:   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.348</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"    \u001b[1m[\u001b[0mBatch \u001b[1;36m350\u001b[0m \u001b[35m/\u001b[0m \u001b[1;36m476\u001b[0m\u001b[1m]\u001b[0m Batch train loss:   \u001b[1;36m0.733\u001b[0m. Mask-only loss:   \u001b[1;36m0.358\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    <span style=\"font-weight: bold\">[</span>Batch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">350</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">476</span><span style=\"font-weight: bold\">]</span> Batch train loss:   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.733</span>. Mask-only loss:   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.358</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"    \u001b[1m[\u001b[0mBatch \u001b[1;36m400\u001b[0m \u001b[35m/\u001b[0m \u001b[1;36m476\u001b[0m\u001b[1m]\u001b[0m Batch train loss:   \u001b[1;36m0.593\u001b[0m. Mask-only loss:   \u001b[1;36m0.311\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    <span style=\"font-weight: bold\">[</span>Batch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">476</span><span style=\"font-weight: bold\">]</span> Batch train loss:   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.593</span>. Mask-only loss:   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.311</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"    \u001b[1m[\u001b[0mBatch \u001b[1;36m450\u001b[0m \u001b[35m/\u001b[0m \u001b[1;36m476\u001b[0m\u001b[1m]\u001b[0m Batch train loss:   \u001b[1;36m0.702\u001b[0m. Mask-only loss:   \u001b[1;36m0.295\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    <span style=\"font-weight: bold\">[</span>Batch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">450</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">476</span><span style=\"font-weight: bold\">]</span> Batch train loss:   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.702</span>. Mask-only loss:   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.295</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m[\u001b[0mEpoch  \u001b[1;36m1\u001b[0m \u001b[35m/\u001b[0m  \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m Train mask-only loss:   \u001b[1;36m0.327\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Epoch  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span> Train mask-only loss:   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.327</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m[\u001b[0mEpoch  \u001b[1;36m1\u001b[0m \u001b[35m/\u001b[0m  \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m Train loss:   \u001b[1;36m0.670\u001b[0m. \u001b[1m[\u001b[0m\u001b[1;36m926\u001b[0m secs\u001b[1m]\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Epoch  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span> Train loss:   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.670</span>. <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">926</span> secs<span style=\"font-weight: bold\">]</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m[\u001b[0mEpoch  \u001b[1;36m1\u001b[0m \u001b[35m/\u001b[0m  \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m Valid mask-only loss:   \u001b[1;36m0.103\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Epoch  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span> Valid mask-only loss:   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.103</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m[\u001b[0mEpoch  \u001b[1;36m1\u001b[0m \u001b[35m/\u001b[0m  \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m Valid loss:   \u001b[1;36m0.209\u001b[0m. \u001b[1m[\u001b[0m\u001b[1;36m926\u001b[0m secs\u001b[1m]\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Epoch  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span> Valid loss:   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.209</span>. <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">926</span> secs<span style=\"font-weight: bold\">]</span>\n</pre>\n"},"metadata":{}}]}]}